{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "# changing n_sampls to 50 for debugging purpose\n",
    "x, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.8, random_state=15)\n",
    "# the more class_sep value, points will be separated more, we will have clear cut decision boundary value.\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15096, 34904)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the frequency of the target variable.\n",
    "list(y).count(1),list(y).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8733, 3767)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test).count(0),list(y_test).count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) \n",
    "\n",
    "# eta0 is your r value\n",
    "# alpha is the Lambda value\n",
    "# tol is tolerance, the stopping criteria, if sees the difference is lesser than mentioned then algorithm gets stopped\n",
    "# Though difference between previous iteration loss, and current loss is 1e-3 in 7th iteration, it is running for 11 epoch's \n",
    "# because n_iter_no_change was set to 5. change n_iter_no_change=7 then it runs for 13 epoch's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.83, NNZs: 15, Bias: -0.282453, T: 37500, Avg. loss: 0.416920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.99, NNZs: 15, Bias: -0.421256, T: 75000, Avg. loss: 0.351793\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.522158, T: 112500, Avg. loss: 0.342380\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.12, NNZs: 15, Bias: -0.599947, T: 150000, Avg. loss: 0.338447\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.15, NNZs: 15, Bias: -0.664380, T: 187500, Avg. loss: 0.336584\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.16, NNZs: 15, Bias: -0.713463, T: 225000, Avg. loss: 0.335459\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.18, NNZs: 15, Bias: -0.751239, T: 262500, Avg. loss: 0.334854\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.18, NNZs: 15, Bias: -0.782405, T: 300000, Avg. loss: 0.334445\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.19, NNZs: 15, Bias: -0.806457, T: 337500, Avg. loss: 0.334080\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.20, NNZs: 15, Bias: -0.827295, T: 375000, Avg. loss: 0.334036\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.20, NNZs: 15, Bias: -0.842327, T: 412500, Avg. loss: 0.333940\n",
      "Total training time: 0.15 seconds.\n",
      "Convergence after 11 epochs took 0.15 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=x_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.47567788,  0.19589413, -0.17415821,  0.37900851, -0.24481811,\n",
       "          0.63622905, -0.49254767, -0.10433643,  0.22645472,  0.19989695,\n",
       "          0.20952843,  0.0019088 , -0.09266827,  0.37707176,  0.02701887]]),\n",
       " (1, 15),\n",
       " array([-0.84232715]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights <-- this is W value\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term <-- this is b value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (dim,1) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w=np.zeros_like(dim)\n",
    "    b=0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=x_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='Red'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=x_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "    assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "    return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    return (1/(1 + np.exp(-1*z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val=sigmoid(z)\n",
    "    assert(val==0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    n=len(y_true)\n",
    "    loss = 0.0 \n",
    "    for (y_true,y_pred) in zip(y_true,y_pred):\n",
    "        loss += ((y_true*np.log10(y_pred)) + ((1-y_true) * np.log10(1-y_pred)))\n",
    "    loss = -1 *(loss/n)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t})- \\frac{λ}{N}w^{(t)})$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    z = np.dot((w.T),x) + b\n",
    "    a = y-sigmoid(z)-(alpha/N)*w\n",
    "    dw = x*a\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "    grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "#     print(np.sum(grad_dw))\n",
    "    assert(np.sum(grad_dw)==2.613689585)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(x_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "    z = np.dot((w.T),x+b)\n",
    "    db = y - sigmoid(z)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "    grad_db=gradient_db(x,y,w,b)\n",
    "    assert(grad_db==-0.5)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(x_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        predict.append(sigmoid(z))\n",
    "    return np.array(predict)\n",
    "# print(1-np.sum(y_train - pred(w,b,x_train))/len(x_train))\n",
    "# print(1-np.sum(y_test  - pred(w,b,x_test))/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(x_train,y_train,x_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    w,b = initialize_weights(x_train[0])\n",
    "    N = len(x_train)\n",
    "    train_log_loss_full=[]\n",
    "    test_log_loss_full=[]\n",
    "    # for every epoch\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # for every data point(X_train,y_train)\n",
    "        y_train_pred = []\n",
    "        y_test_pred = []\n",
    "        for x_t,y_t in zip(x_train,y_train):\n",
    "            dw = gradient_dw(x_t,y_t,w,b,alpha,N)            #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "            db = gradient_db(x_t,y_t,w,b)            #compute gradient w.r.to b (call the gradient_db() function\n",
    "            w = w - (eta0*dw)#update w, b\n",
    "            b = b - (eta0*db)\n",
    "        print(\"Final w,b values -->\",w,b)\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "\n",
    "#         #compute the loss between predicted and actual values (call the loss function)\n",
    "#         #compute the loss between predicted and actual values (call the loss function)\n",
    "        y_train_pred = pred(w,b,x_train)\n",
    "        train_logloss = logloss(y_train,y_train_pred)\n",
    "        print(\"train_logloss-->\",train_logloss)\n",
    "#         print(\"epoch-->\",epoch,\"train_logloss-->\",train_logloss)\n",
    "#         # store all the train loss values in a list\n",
    "#         # store all the test loss values in a list\n",
    "        train_log_loss_full.append(train_logloss)\n",
    "#         print(train_log_loss_full)\n",
    "        for i in range(len(x_test)):\n",
    "            y_test_pred.append(sigmoid(np.dot(w.T,x_test[i])+b))\n",
    "            \n",
    "        test_logloss = logloss(y_test,y_test_pred)\n",
    "        test_log_loss_full.append(test_logloss)\n",
    "        print(\"epoch -->\",epoch,\"train_log_loss_full -->\",train_log_loss_full,\"test_log_loss_full-->\",test_log_loss_full)\n",
    "#         if ((epoch>0) & ((train_log_loss_full[epoch-1] - train_log_loss_full[epoch])<0.0001)):\n",
    "#             break\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "# #         you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "        \n",
    "        \n",
    "    return w,b,train_log_loss_full,test_log_loss_full\n",
    "#     return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUquz7LFEZ6E",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 5.75261539e-03 -3.06766401e-03 -3.37880077e-03 -3.60029111e-03\n",
      " -2.77498417e-05 -7.09921394e-03  5.91093895e-03  6.77637408e-05\n",
      " -3.84038920e-03 -2.47529310e-05 -5.05300964e-04  3.51630191e-04\n",
      " -6.80507919e-04 -3.12752164e-03 -3.12105433e-03] 0.007420280175534813\n",
      "train_logloss--> 0.303840481032976\n",
      "epoch --> 0 train_log_loss_full --> [0.303840481032976] test_log_loss_full--> [0.3038530383091434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:02<01:57,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 1.15954996e-02 -6.16833018e-03 -6.85925336e-03 -7.24845250e-03\n",
      " -8.07163826e-05 -1.43114103e-02  1.18845052e-02  1.24422989e-04\n",
      " -7.77075893e-03 -3.25831729e-05 -9.92589311e-04  7.11861703e-04\n",
      " -1.38463775e-03 -6.29482283e-03 -6.32642354e-03] 0.014838250553306797\n",
      "train_logloss--> 0.3067280820437076\n",
      "epoch --> 1 train_log_loss_full --> [0.303840481032976, 0.3067280820437076] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:04<01:55,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 1.75304013e-02 -9.30242128e-03 -1.04437122e-02 -1.09453330e-02\n",
      " -1.59666795e-04 -2.16384802e-02  1.79211233e-02  1.69496148e-04\n",
      " -1.17933798e-02 -2.32103867e-05 -1.46093196e-03  1.08067939e-03\n",
      " -2.11277218e-03 -9.50266583e-03 -9.61801301e-03] 0.022251551238761394\n",
      "train_logloss--> 0.3096952384186599\n",
      "epoch --> 2 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:06<01:48,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 2.35590599e-02 -1.24703559e-02 -1.41345284e-02 -1.46917765e-02\n",
      " -2.65373439e-04 -2.90822853e-02  2.40211813e-02  2.02496620e-04\n",
      " -1.59105315e-02  3.64336405e-06 -1.90937815e-03  1.45805311e-03\n",
      " -2.86528457e-03 -1.27518110e-02 -1.29977227e-02] 0.029657755268103696\n",
      "train_logloss--> 0.312744441770025\n",
      "epoch --> 3 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:09<01:43,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 2.96832008e-02 -1.56725478e-02 -1.79340433e-02 -1.84886196e-02\n",
      " -3.98612212e-04 -3.66446510e-02  3.01850287e-02  2.22933960e-04\n",
      " -2.01244976e-02  4.82529618e-05 -2.33696118e-03  1.84393687e-03\n",
      " -3.64253769e-03 -1.60430149e-02 -1.64674421e-02] 0.03705437136882065\n",
      "train_logloss--> 0.3158782324111606\n",
      "epoch --> 4 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:11<01:46,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.03590453 -0.0189094  -0.02184458 -0.02233669 -0.00056016 -0.04432736\n",
      "  0.03641297  0.00023032 -0.02443756  0.00011089 -0.0027427   0.00223827\n",
      " -0.00444488 -0.01937703 -0.02002904] 0.0444388472544998\n",
      "train_logloss--> 0.31909919561338185\n",
      "epoch --> 5 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:15<01:57,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.04222473 -0.02218133 -0.02586845 -0.0262368  -0.0007508  -0.05213215\n",
      "  0.04270528  0.00022415 -0.02885199  0.00019182 -0.0031256   0.00264097\n",
      " -0.00527266 -0.02275459 -0.02368438] 0.051808573476605814\n",
      "train_logloss--> 0.32240995728324884\n",
      "epoch --> 6 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:17<01:54,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.04864545 -0.02548871 -0.03000791 -0.03018975 -0.0009713  -0.06006069\n",
      "  0.04906216  0.00020393 -0.03337005  0.0002913  -0.00348467  0.00305193\n",
      " -0.00612618 -0.02617644 -0.02743527] 0.05916088785101832\n",
      "train_logloss--> 0.32581317904018736\n",
      "epoch --> 7 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:19<01:47,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.0551683  -0.02883194 -0.03426521 -0.03419633 -0.00122243 -0.06811459\n",
      "  0.05548379  0.00016918 -0.03799397  0.0004096  -0.00381889  0.00347106\n",
      " -0.00700577 -0.02964329 -0.03128351] 0.06649308047122304\n",
      "train_logloss--> 0.32931155267983014\n",
      "epoch --> 8 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:21<01:36,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.06179486 -0.03221139 -0.03864253 -0.03825729 -0.00150496 -0.0762954\n",
      "  0.06197029  0.0001194  -0.04272597  0.00054695 -0.00412725  0.00389819\n",
      " -0.0079117  -0.03315583 -0.03523084] 0.07380239931320702\n",
      "train_logloss--> 0.3329077940150195\n",
      "epoch --> 9 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:23<01:26,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 6.85266535e-02 -3.56274309e-02 -4.31420076e-02 -4.23733659e-02\n",
      " -1.81964984e-03 -8.46045860e-02  6.85217039e-02  5.41043360e-05\n",
      " -4.75682223e-02  7.03603922e-04 -4.40874289e-03  4.33319305e-03\n",
      " -8.84424521e-03 -3.67147671e-02 -3.92789659e-02] 0.08108605642928117\n",
      "train_logloss--> 0.33660463609365404\n",
      "epoch --> 10 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:25<01:24,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 7.53651416e-02 -3.90804108e-02 -4.77657147e-02 -4.65452755e-02\n",
      " -2.16724082e-03 -9.30435118e-02  7.51380560e-02 -2.71835667e-05\n",
      " -5.25228481e-02  8.79783875e-04 -4.66235245e-03  4.77587823e-03\n",
      " -9.80366139e-03 -4.03207474e-02 -4.34295217e-02] 0.08834123471934868\n",
      "train_logloss--> 0.34040482180108583\n",
      "epoch --> 11 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:27<01:22,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.08231173 -0.04257067 -0.05251565 -0.05077369 -0.00254847 -0.10161346\n",
      "  0.08181929 -0.00012494 -0.05759193  0.00107571 -0.00488708  0.00522605\n",
      " -0.01079017 -0.04397441 -0.04768409] 0.09556509525874415\n",
      "train_logloss--> 0.3443110958634447\n",
      "epoch --> 12 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:30<01:21,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.08936777 -0.04609855 -0.05739375 -0.05505927 -0.00296405 -0.11031562\n",
      "  0.0885653  -0.00023962 -0.06277749  0.0012916  -0.00508191  0.0056835\n",
      " -0.01180398 -0.04767637 -0.05204419] 0.1027547851517428\n",
      "train_logloss--> 0.3483261962782449\n",
      "epoch --> 13 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:33<01:29,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.0965345  -0.04966435 -0.06240183 -0.05940261 -0.00341468 -0.11915105\n",
      "  0.09537592 -0.00037169 -0.06808147  0.00152765 -0.00524589  0.00614799\n",
      " -0.01284528 -0.0514272  -0.05651124] 0.10990744586946964\n",
      "train_logloss--> 0.35245284520854103\n",
      "epoch --> 14 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:39<02:08,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.10381313 -0.05326838 -0.06754165 -0.06380428 -0.00390105 -0.12812071\n",
      "  0.10225091 -0.00052159 -0.07350576  0.00178403 -0.00537802  0.00661926\n",
      " -0.01391421 -0.05522746 -0.0610866 ] 0.1170202220204862\n",
      "train_logloss--> 0.3566937393873925\n",
      "epoch --> 15 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:44<02:12,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.11120474 -0.05691091 -0.07281483 -0.06826481 -0.00442382 -0.13722543\n",
      "  0.10918998 -0.00068974 -0.07905214  0.00206093 -0.00547738  0.00709703\n",
      " -0.0150109  -0.05907765 -0.06577153] 0.12409027049198504\n",
      "train_logloss--> 0.36105154009016144\n",
      "epoch --> 16 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:48<02:11,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.11871033 -0.06059221 -0.0782229  -0.07278468 -0.00498361 -0.14646592\n",
      "  0.11619277 -0.00087656 -0.08472232  0.00235848 -0.00554302  0.00758102\n",
      " -0.01613546 -0.06297826 -0.07056717] 0.13111476988971502\n",
      "train_logloss--> 0.36552886274217233\n",
      "epoch --> 17 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [00:52<02:12,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.12633081 -0.06431253 -0.08376726 -0.07736432 -0.00558105 -0.15584275\n",
      "  0.12325887 -0.00108245 -0.0905179   0.00267684 -0.00557405  0.0080709\n",
      " -0.01728796 -0.0669297  -0.0754746 ] 0.1380909301956841\n",
      "train_logloss--> 0.3701282662397279\n",
      "epoch --> 18 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:57<02:10,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.13406699 -0.0680721  -0.08944918 -0.0820041  -0.00621671 -0.16535634\n",
      "  0.1303878  -0.0013078  -0.09644038  0.00301611 -0.00556961  0.00856635\n",
      " -0.01846844 -0.07093239 -0.08049475] 0.1450160025547503\n",
      "train_logloss--> 0.3748522420714859\n",
      "epoch --> 19 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [01:00<02:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.14191954 -0.0718711  -0.09526981 -0.08670434 -0.00689114 -0.17500698\n",
      "  0.137579   -0.00155297 -0.10249113  0.0033764  -0.00552886  0.00906701\n",
      " -0.01967692 -0.07498665 -0.08562845] 0.15188728909468063\n",
      "train_logloss--> 0.37970320333573615\n",
      "epoch --> 20 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [01:04<01:50,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.14988904 -0.07570974 -0.10123013 -0.09146532 -0.00760487 -0.18479481\n",
      "  0.14483189 -0.00181831 -0.10867143  0.00375777 -0.00545099  0.00957252\n",
      " -0.02091337 -0.0790928  -0.09087639] 0.1587021526793682\n",
      "train_logloss--> 0.38468347375626216\n",
      "epoch --> 21 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [01:08<01:53,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.15797597 -0.07958817 -0.10733102 -0.09628723 -0.00835839 -0.19471982\n",
      "  0.15214578 -0.00210415 -0.11498242  0.0041603  -0.00533525  0.01008251\n",
      " -0.02217776 -0.08325109 -0.09623917] 0.16545802649200927\n",
      "train_logloss--> 0.3897952768050829\n",
      "epoch --> 22 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [01:16<02:19,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.16618066 -0.08350653 -0.11357315 -0.10117021 -0.00915215 -0.20478183\n",
      "  0.15951995 -0.0024108  -0.12142509  0.00458401 -0.00518092  0.01059659\n",
      " -0.02347    -0.08746171 -0.10171722] 0.1721524233440783\n",
      "train_logloss--> 0.3950407250442885\n",
      "epoch --> 23 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [01:22<02:20,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.17450332 -0.08746492 -0.11995709 -0.10611436 -0.00998657 -0.21498054\n",
      "  0.16695362 -0.00273854 -0.12800032  0.00502892 -0.00498734  0.01111434\n",
      " -0.02478998 -0.09172481 -0.10731086] 0.17878294460737437\n",
      "train_logloss--> 0.40042180980122943\n",
      "epoch --> 24 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [01:27<02:13,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.18294405 -0.09146343 -0.12648321 -0.11111967 -0.01086203 -0.22531547\n",
      "  0.17444596 -0.00308765 -0.13470884  0.00549501 -0.00475387  0.01163537\n",
      " -0.02613756 -0.09604051 -0.11302026] 0.1853472886698999\n",
      "train_logloss--> 0.4059403912910841\n",
      "epoch --> 25 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [01:33<02:08,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.19150281 -0.09550212 -0.13315174 -0.1161861  -0.01177889 -0.23578598\n",
      "  0.18199607 -0.00345838 -0.14155124  0.00598224 -0.00447994  0.01215924\n",
      " -0.02751258 -0.10040883 -0.11884545] 0.19184325882205436\n",
      "train_logloss--> 0.4115981892986756\n",
      "epoch --> 26 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [01:37<01:55,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.20017945 -0.09958102 -0.13996273 -0.12131353 -0.01273745 -0.2463913\n",
      "  0.18960302 -0.00385094 -0.14852796  0.00649055 -0.00416503  0.01268553\n",
      " -0.02891483 -0.10482977 -0.12478634] 0.19826877048746933\n",
      "train_logloss--> 0.4173967745266996\n",
      "epoch --> 27 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [01:40<01:39,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.20897367 -0.10370013 -0.1469161  -0.12650177 -0.01373798 -0.25713049\n",
      "  0.19726582 -0.00426556 -0.1556393   0.00701985 -0.00380866  0.01321382\n",
      " -0.03034408 -0.10930328 -0.13084268] 0.20462185772242444\n",
      "train_logloss--> 0.4233375607109472\n",
      "epoch --> 28 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [01:47<01:46,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.21788506 -0.10785943 -0.15401156 -0.13175058 -0.01478072 -0.26800248\n",
      "  0.20498343 -0.00470241 -0.16288541  0.00757004 -0.00341042  0.01374367\n",
      " -0.03180008 -0.11382924 -0.13701408] 0.21090067891906097\n",
      "train_logloss--> 0.4294217975942367\n",
      "epoch --> 29 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [01:51<01:39,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.22691308 -0.11205886 -0.16124868 -0.13705963 -0.01586587 -0.27900603\n",
      "  0.21275478 -0.00516166 -0.17026628  0.00814095 -0.00296994  0.01427464\n",
      " -0.03328254 -0.11840748 -0.14330001] 0.2171035216601711\n",
      "train_logloss--> 0.4356505648400306\n",
      "epoch --> 30 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [01:55<01:28,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.23605706 -0.11629833 -0.16862689 -0.14242854 -0.01699357 -0.2901398\n",
      "  0.22057876 -0.00564346 -0.17778176  0.00873244 -0.00248692  0.0148063\n",
      " -0.03479115 -0.12303779 -0.14969982] 0.2232288066867945\n",
      "train_logloss--> 0.4420247669543585\n",
      "epoch --> 31 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [01:59<01:18,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.24531624 -0.12057773 -0.17614542 -0.14785685 -0.01816394 -0.30140227\n",
      "  0.22845424 -0.00614792 -0.18543156  0.00934431 -0.00196109  0.01533823\n",
      " -0.03632558 -0.1277199  -0.15621272] 0.2292750909539269\n",
      "train_logloss--> 0.44854512927077944\n",
      "epoch --> 32 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [02:03<01:10,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.25468969 -0.12489691 -0.18380338 -0.15334407 -0.01937708 -0.31279184\n",
      "  0.23638002 -0.00667515 -0.19321524  0.00997633 -0.00139226  0.01587\n",
      " -0.03788546 -0.1324535  -0.16283777] 0.23524106976378514\n",
      "train_logloss--> 0.4552121950384221\n",
      "epoch --> 33 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [02:06<01:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.26417642 -0.1292557  -0.19159971 -0.15888961 -0.02063301 -0.32430675\n",
      "  0.24435492 -0.00722523 -0.20113222  0.01062828 -0.00078029  0.0164012\n",
      " -0.03947042 -0.13723822 -0.16957394] 0.2411255779801074\n",
      "train_logloss--> 0.46202632363742996\n",
      "epoch --> 34 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [02:08<00:51,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 2.73775301e-01 -1.33653889e-01 -1.99533230e-01 -1.64492855e-01\n",
      " -2.19317560e-02 -3.35945150e-01  2.52377702e-01 -7.79823593e-03\n",
      " -2.09181791e-01  1.12998792e-02 -1.25069257e-04  1.69314088e-02\n",
      " -4.10800409e-02 -1.42073661e-01 -1.76420044e-01] 0.24692759034031864\n",
      "train_logloss--> 0.4689876899304231\n",
      "epoch --> 35 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [02:11<00:44,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.28348511 -0.13809124 -0.2076026  -0.17015311 -0.02327328 -0.34770508\n",
      "  0.26044713 -0.0083942  -0.2173631   0.01199084  0.00057344  0.01746024\n",
      " -0.04271392 -0.14695937 -0.1833748 ] 0.25264622089485667\n",
      "train_logloss--> 0.4760962847427931\n",
      "epoch --> 36 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [02:13<00:38,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.29330454 -0.1425675  -0.21580635 -0.17586963 -0.02465751 -0.35958448\n",
      "  0.26856193 -0.00901317 -0.22567516  0.01270085  0.00131522  0.01798729\n",
      " -0.0443716  -0.15189485 -0.19043682] 0.2582807216143058\n",
      "train_logloss--> 0.4833519164493102\n",
      "epoch --> 37 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [02:15<00:31,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.30323216 -0.14708235 -0.2241429  -0.18164163 -0.02608435 -0.37158121\n",
      "  0.27672084 -0.00965514 -0.2341169   0.01342959  0.00210022  0.0185122\n",
      " -0.04605264 -0.15687958 -0.19760461] 0.26383048021485456\n",
      "train_logloss--> 0.49075421363010835\n",
      "epoch --> 38 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [02:18<00:30,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.31326648 -0.15163549 -0.23261055 -0.18746827 -0.02755368 -0.38369303\n",
      "  0.28492257 -0.0103201  -0.24268708  0.01417669  0.00292834  0.0190346\n",
      " -0.04775658 -0.16191299 -0.20487656] 0.26929501726096083\n",
      "train_logloss--> 0.4983026287457122\n",
      "epoch --> 39 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [02:21<00:27,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.32340593 -0.15622656 -0.24120749 -0.19334868 -0.02906533 -0.39591766\n",
      "  0.29316584 -0.01100805 -0.2513844   0.01494178  0.00379943  0.01955415\n",
      " -0.04948291 -0.16699448 -0.21225101] 0.2746739826106891\n",
      "train_logloss--> 0.5059964427687706\n",
      "epoch --> 40 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [02:24<00:24,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.33364885 -0.16085519 -0.2499318  -0.19928192 -0.0306191  -0.40825272\n",
      "  0.30144935 -0.01171893 -0.26020742  0.01572449  0.00471331  0.02007052\n",
      " -0.05123117 -0.17212343 -0.21972619] 0.27996715127433747\n",
      "train_logloss--> 0.513834770699874\n",
      "epoch --> 41 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [02:26<00:21,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.34399353 -0.16552096 -0.25878149 -0.20526706 -0.03221477 -0.42069582\n",
      "  0.30977182 -0.0124527  -0.26915464  0.01652439  0.00566973  0.02058339\n",
      " -0.05300084 -0.17729918 -0.22730027] 0.2851744187600475\n",
      "train_logloss--> 0.521816567886235\n",
      "epoch --> 42 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [02:30<00:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.35443821 -0.17022347 -0.26775447 -0.21130309 -0.03385209 -0.43324449\n",
      "  0.31813196 -0.01320928 -0.27822444  0.01734109  0.00666844  0.02109246\n",
      " -0.05479142 -0.18252104 -0.23497136] 0.29029579598193483\n",
      "train_logloss--> 0.5299406370552029\n",
      "epoch --> 43 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [02:33<00:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.36498104 -0.17496224 -0.27684859 -0.217389   -0.03553078 -0.44589624\n",
      "  0.32652848 -0.01398861 -0.28741513  0.01817413  0.00770913  0.02159746\n",
      " -0.0566024  -0.18778833 -0.24273748] 0.29533140380631495\n",
      "train_logloss--> 0.5382056359698301\n",
      "epoch --> 44 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [02:36<00:14,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.37562016 -0.17973683 -0.28606161 -0.22352375 -0.03725053 -0.45864855\n",
      "  0.33496013 -0.01479058 -0.29672497  0.0190231   0.00879146  0.02209812\n",
      " -0.05843326 -0.1931003  -0.25059665] 0.30028146731044053\n",
      "train_logloss--> 0.5466100856108463\n",
      "epoch --> 45 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301, 0.5466100856108463] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248, 0.5483224242622567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [02:39<00:12,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.38635367 -0.18454672 -0.29539128 -0.22970626 -0.03901103 -0.47149888\n",
      "  0.34342563 -0.01561509 -0.30615211  0.01988752  0.00991506  0.0225942\n",
      " -0.06028347 -0.19845622 -0.25854682] 0.3051463098257469\n",
      "train_logloss--> 0.5551523787879938\n",
      "epoch --> 46 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301, 0.5466100856108463, 0.5551523787879938] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248, 0.5483224242622567, 0.5569343020292546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [02:42<00:09,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.39717961 -0.18939142 -0.30483524 -0.23593547 -0.04081191 -0.48444467\n",
      "  0.35192375 -0.01646202 -0.31569469  0.02076695  0.01107956  0.02308546\n",
      " -0.06215252 -0.20385535 -0.26658589] 0.30992634683411713\n",
      "train_logloss--> 0.5638307890845743\n",
      "epoch --> 47 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301, 0.5466100856108463, 0.5551523787879938, 0.5638307890845743] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248, 0.5483224242622567, 0.5569343020292546, 0.5656837292165636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [02:46<00:06,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.40809601 -0.19427038 -0.31439115 -0.24221027 -0.04265281 -0.49748337\n",
      "  0.36045325 -0.01733124 -0.32535076  0.02166091  0.01228451  0.02357171\n",
      " -0.06403989 -0.2092969  -0.27471177] 0.31462207978146883\n",
      "train_logloss--> 0.5726434800410074\n",
      "epoch --> 48 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301, 0.5466100856108463, 0.5551523787879938, 0.5638307890845743, 0.5726434800410074] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248, 0.5483224242622567, 0.5569343020292546, 0.5656837292165636, 0.5745688543231027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [02:48<00:02,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w,b values --> [ 0.4191009  -0.19918307 -0.3240566  -0.24852955 -0.04453333 -0.51061243\n",
      "  0.36901293 -0.01822262 -0.33511835  0.02256894  0.01352949  0.02405274\n",
      " -0.06594506 -0.21478012 -0.28292232] 0.31923408986798185\n",
      "train_logloss--> 0.5815885144865922\n",
      "epoch --> 49 train_log_loss_full --> [0.303840481032976, 0.3067280820437076, 0.3096952384186599, 0.312744441770025, 0.3158782324111606, 0.31909919561338185, 0.32240995728324884, 0.32581317904018736, 0.32931155267983014, 0.3329077940150195, 0.33660463609365404, 0.34040482180108583, 0.3443110958634447, 0.3483261962782449, 0.35245284520854103, 0.3566937393873925, 0.36105154009016144, 0.36552886274217233, 0.3701282662397279, 0.3748522420714859, 0.37970320333573615, 0.38468347375626216, 0.3897952768050829, 0.3950407250442885, 0.40042180980122943, 0.4059403912910841, 0.4115981892986756, 0.4173967745266996, 0.4233375607109472, 0.4294217975942367, 0.4356505648400306, 0.4420247669543585, 0.44854512927077944, 0.4552121950384221, 0.46202632363742996, 0.4689876899304231, 0.4760962847427931, 0.4833519164493102, 0.49075421363010835, 0.4983026287457122, 0.5059964427687706, 0.513834770699874, 0.521816567886235, 0.5299406370552029, 0.5382056359698301, 0.5466100856108463, 0.5551523787879938, 0.5638307890845743, 0.5726434800410074, 0.5815885144865922] test_log_loss_full--> [0.3038530383091434, 0.3067538992063044, 0.30973504634018456, 0.312799000089282, 0.3159483299758476, 0.31918565085533673, 0.32251361852111776, 0.3259349247048508, 0.329452291458781, 0.3330684649126556, 0.3367862084055183, 0.34060829500085593, 0.3445374994025338, 0.3485765892985977, 0.3527283161700389, 0.35699540561188076, 0.36138054722445423, 0.3658863841428988, 0.37051550228280444, 0.3752704193890859, 0.3801535739834809, 0.3851673143130754, 0.3903138874078787, 0.3955954283593874, 0.40101394993406264, 0.40657133263557943, 0.41226931532759215, 0.41810948652416674, 0.42409327644870326, 0.4302219499532084, 0.4364966003794602, 0.442918144431082, 0.44948731811206444, 0.4562046737722702, 0.4630705782851727, 0.4700852123670339, 0.47724857103109464, 0.4845604651549109, 0.4920205241244331, 0.4996281995049219, 0.5073827696767292, 0.5152833453635417, 0.5233288759718023, 0.5315181566533911, 0.5398498359984248, 0.5483224242622567, 0.5569343020292546, 0.5656837292165636, 0.5745688543231027, 0.5835877238323354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:51<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.000001\n",
    "N=len(x_train)\n",
    "epochs=50\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "w,b,train_log_loss_full,test_log_loss_full=train(x_train,y_train,x_test,y_test,epochs,alpha,eta0)\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hU1dbA4d8ihF5C7xCaIjV0UURAREAplyJdioCoiFxFBUUQbFg+vCKWi4qiKEVRLwpeFCUKIgpINYiEooTeIUDKzKzvjzlwxxiSAJlMMrPe55knp+xzztqZSdbsU/YWVcUYY4xJKVegAzDGGJM9WYIwxhiTKksQxhhjUmUJwhhjTKosQRhjjEmVJQhjjDGpsgRhTAgSERWRGoGOw2RvliBMjiYiu0WkXRYfs4WInBGRwqmsWy8ioy5xf7tF5JyIxPu8ZmRexMZcHksQxlwiVf0RiAN6+C4XkbpAbWDuZey2s6oW8nldUpIxxh8sQZigJSLDRSRWRI6JyCIRKe8sFxF5SUQOichJEdnk/HNHRDqJSIyInBaRvSIy9iK7nw3ckWLZHcBiVT0qIvlEZI6IHBWREyKyRkTKXEYdBovIDyLyihPrbyJyk8/68k7djjl1He6zLkxEHhWRHU591olIJZ/dtxOR7SJyXEReFRG51PhMcLMEYYKSiLQFngVuB8oBfwDznNXtgVbAVUAE0Bs46qx7G7hLVQsDdYFvL3KI94EbRKSyc7xcQD/gPWf9IKAoUAkoAYwEzl1mdZoDO4GSwCTgExEp7qybi7c1Ux7oCTzjk0AeAPoCnYAiwFDgrM9+bwOaAg3w/p5uucz4TJCyBGGCVX9glqr+oqqJwHighYhEAslAYaAWIKq6VVX3O9slA7VFpIiqHlfVX1LbuaruAb4DBjiLbgLyAYt99lMCqKGqblVdp6qn0oj3M6elcf413GfdIeBfqpqsqvOBbcCtTmugJfCIqiao6gbgLWCgs90wYIKqblOvjap61Ge/U1X1hKr+CSwHotKIz4QgSxAmWJXH22oAQFXj8bYSKqjqt8AM4FXgoIjMFJEiTtEeeL9x/yEi34lIizSO4XuaaSDwoaomO/PvA0uBeSKyT0SeF5HwNPbVTVUjfF5v+qzbq3/tVfMPp37lgWOqejrFugrOdCVgRxrHPOAzfRYolEZZE4IsQZhgtQ+ocn5GRAri/Ua/F0BVp6tqY6AO3lNNDznL16hqV6A08BmwII1jfAJUEJE2QHf+d3oJ59v+ZFWtDVyH93ROymsWGVUhxfWByk799gHFU9xNVfl8HYE9QPXLPKYxliBMUAh3Lgqff+UGPgSGiEiUiOQFngF+UtXdItJURJo73+jPAAmAW0TyiEh/ESnqtAROAe6LHVRVzwAfA+8Af6jq2vPrRKSNiNQTkTBnP8lp7SsdpYHRIhIuIr2Aa4AlzmmuVcCzTr3rA3cCHzjbvQU8KSI1nQvz9UWkxGXGYEKQJQgTDJbgvQB8/vWEqn4DPA4sBPbj/SbdxylfBHgTOI73lMxR4EVn3UBgt4icwnth+fw1houZjbel8l6K5WXxJo9TwFa81yvmpLGfz1M8B/Gpz7qfgJrAEeBpoKfPtYS+QCTe1sSnwCRV/dpZNw1vC+grJ463gfzp1MeYC8QGDDIm+xKRwcAwVW0Z6FhM6LEWhDHGmFRZgjDGGJMqO8VkjDEmVdaCMMYYk6rcgQ4gs5QsWVIjIyPTLHPmzBkKFiyYNQFlM6Fad6t3aLF6X7p169YdUdVSqa0LmgQRGRnJ2rVr0ywTHR1N69atsyagbCZU6271Di1W70snIn9cbJ2dYjLGGJMqSxDGGGNSZQnCGGNMqoLmGkRqkpOTiYuLIyEhAYCiRYuydevWAEcVGNmp7vny5aNixYqEh6fVuakxJtCCOkHExcVRuHBhIiMjERFOnz5N4cJ/G0Y4JGSXuqsqR48eJS4ujqpVqwY6HGNMGoL6FFNCQgIlSpTARlLMPkSEEiVKXGjVGWOyr6BOEIAlh2zI3hNjcoagTxDGGBPUtn5BmQPRftm1JQg/Onr0KFFRUURFRVG2bFkqVKhwYT4pKSlD+xgyZAjbtm3L8DHfeustxowZc7khX+ByuYiIiLji/Rhj/Oj3pehHgym990vwXO54VBcX1BepA61EiRJs2LABgCeeeIJChQoxduzYv5RRVVSVXLlSz9XvvPOO3+M0xuRAscvQ+QOIlSqMPvcQX5CLsEw+hLUgAiA2Npa6desycuRIGjVqxP79+xkxYgRNmjShTp06TJky5ULZli1bsmHDhgvf6MeNG0eDBg1o0aIFhw4dSvM4u3btok2bNtSvX5+uXbsSFxcHwPbt22nevDnNmjXj8ccfT7el4PF4eOCBB6hbty716tXj448/BmDv3r20bNmSqKgo6taty6pVq3C5XAwcOJB69epRt25dpk+ffoW/LWPM3+z8Dp3Xn11UoF/CODpeHUFYrsy/thcyLYjJn//K5j3HCQvLvBxbu3wRJnWuc1nbxsTE8M477/DGG28AMHXqVIoXL47L5aJNmzb07NmT2rVr/2WbkydPcuONNzJ16lQeeOABZs2axbhx4y56jHvuuYdhw4bRv39/pk+fzpgxY/j444+57777GDt2LL169WLGjBnpxvrRRx8RExPDxo0bOXz4ME2bNqVVq1bMmTOHzp0788gjj+B2uzl37hzr1q3jyJEjbN68GYATJ05c1u/HGHMRf6xC5/bhTy1Dn4RxTB3QirCD/nnGyVoQAVK9enWaNm16YX7u3Lk0atSIRo0asXXrVmJiYv62Tf78+enYsSMAjRs3Zvfu3Wke46effqJPH+8wzH379mXFihUXlvfo0QOAfv36pRvrypUr6devH2FhYZQtW5aWLVuydu1amjZtyltvvcXkyZPZsmULhQoVokaNGmzbto3777+fpUuXUrRo0Qz9PowxGbDnZ/SDnuz1lOD2c+N4ql9rbrqmjN8OFzItiEmd62Sbh8WAv3TNu337dl5++WV+/vlnIiIiGDBgQKrPCeTJk+fCdFhYGC6XK0tivdigUm3btiU6OprFixfTv39/xo8fT//+/dm0aRNffvkl06dPZ+HChcycOTNL4jQmqO39BZ3TnQPuovQ6N44n+rahfZ2yfj2ktSCygVOnTlG4cGGKFCnC/v37Wbp0aabs99prr2XBggUAzJ8/n1atWgHQrFkzPv30UwDmzZuX7n5atWrFvHnzcLvdHDx4kB9++IEmTZrwxx9/ULZsWUaMGMHgwYNZv349hw8fRlXp1asXkydP5pdffsmUuhgT0vZtQN/vxiFXQXqeHc9jfdrSsV45vx82ZFoQ2VmjRo2oXbs2devWpVq1alx//fWZst8ZM2Zw55138uyzz1KyZEnee+89AKZPn87AgQN57rnn6NSpU7qngXr27Mnq1atp0KABIsK0adMoXbo0s2bNYtq0aYSHh1OoUCHmzJnDnj17uPPOO1FVRITnnnsuU+piTMjavwl9rytHk/PS8+x4Hu59E7fVL581xz5/m2VOfzVu3FhTiomJ+cv8qVOn/lYmVPjWPT4+Xj0ej6qqvv/++9q9e/csjyfle+Mvy5cvz5LjZDdW7yCxf7N6pkbq4SnVteW4Wbpw3Z5Ui11JvYG1epH/q9aCCEFr1qxhzJgxeDweihUrZs9aGJMdHYxB3+vCsaRc9Dj7KGN63kz3RhWzNARLECGodevWFx7gM8ZkQ4e2orM7czwRepx9lNE929OjcdYmB7CL1MYYk70c+g2d3ZkTCR56nnuUUT1vCUhyAEsQxhiTfRz+HZ3dmZPn3PRMeJS7u99CzwAlB7AEYYwx2cPhbei7t3LyXDI9E8YzsnsHejWpFNCQ7BqEMcYE2qHf0Hdv42SCmx4Jj3JX944BTw5gLQi/yozuvgFmzZrFgQMHUl03YMAAPvvssyuOddmyZXTr1u2K92OMuUSHtqLv3saJBDc9EsZzd49O3J4NkgNYC8KvMtLdd0bMmjWLRo0aUbasfx+rN8ZksYMx3ruVEjz0SniUUb068o+GgbvmkJK1IAJk9uzZNGvWjKioKO655x48Hk+qXWXPnz+fDRs20Lt373RbHl9//TVRUVHUq1eP4cOHXyi7aNEiGjVqxA033MB9992XbkvhyJEjdOnShfr163PdddexZcsWAL799lsaNGhAVFQUjRo14syZM6l2+W2MyYCDMXh8ksPo2ztlq+QAodSC+HIc+feuh7BMrHLZetBx6iVvtmXLFj799FNWrVpF7ty5GTFiBPPmzaN69ep/6yo7IiKCV155hRkzZhAVFXXRfZ49e5ahQ4cSHR1N9erV6d+/PzNnzmTo0KHcc889LF26lNq1a3P77benG9/jjz9O8+bNWbRoEV999RWDBw9m7dq1vPDCC8ycOZPmzZsTHx9Pvnz5Uu3y2xiTjoO/4nnX+5zD7QkTGNO7I50bZFH3GZfAWhABsGzZMtasWUOTJk2Iioriu+++Y8eOHVfUVfbWrVupWbMm1atXB+COO+7g+++/JyYmhquvvprKlSsjIvTt2zfdfa1cuZKBAwcC0L59e/bt28eZM2e4/vrrGTNmDK+88gqnTp0iLCws1S6/jTFp2L8Jz7u3OcnhMR7s2ylbJgcIpRZEx6mcyybdfasqQ4cO5cknn/zbusvtKlsv0iX3xZZfyr7Oz0+YMIEuXbqwePFimjZtSnR09EW7/DbGpGLfejzvdeNIUjh9Eh7j4X4d6FDX/72yXi6/tiBEpIOIbBORWBH529BnIjJYRA6LyAbnNcxnndtn+SJ/xpnV2rVrx4IFCzhy5Ajgvdvpzz//vGhX2YULF+b06dNp7rN27dps376dnTt3AjBnzhxuvPFG6tSpw7Zt24iLi0NVmT9/frrxtWrVig8++ADwtnYqVqxIwYIF2bFjB/Xr12f8+PE0bNiQbdu2pdrltzEmFXFr8czuwqGkvPROfJxHB3TK1skB/NiCEJEw4FXgZiAOWCMii1Q15VBp81V1VCq7OKeqFz/pnoPVq1ePSZMm0a5dOzweD+Hh4bzxxhuEhYWl2lX2kCFDGDZsGPnz5+fnn3/+y8BB5xUoUIC3336b7t2743a7ad68OcOHDydPnjzMmDGDLl26UKZMGZo2bcqxY8fSjG/KlCkMGTKE+vXrU6hQoQud+b344ousWLGCXLlyUb9+fdq3b8+cOXP+1uW3MSaFP1fjmdODA67C9Et6jCfuuIXWV5cOdFTpu1g3r1f6AloAS33mxwPjU5QZDMy4yPbxl3I86+774k6fPq2nTp1Sj8ejw4cP1+nTpwc6JOvu28+s3tnIrpXqfqqs/vlELb1hwhxduf1wph8iJ3b3XQHY4zMfBzRPpVwPEWkF/A78U1XPb5NPRNYCLmCqqv7taTARGQGMAChTpgzR0dF/WV+0aNG/nJpxu93pnqoJRi+//DLz588nKSmJhg0b0qdPn4D/HhISEv72fvlDfHx8lhwnu7F6Zw8RxzdRd/NT7PGU5I7kRxnQuCzJcVuIjsvc4/it3hfLHFf6AnoBb/nMDwReSVGmBJDXmR4JfOuzrrzzsxqwG6ie1vGsBZG27FZ3a0H4l9U7G/j9K3VPKa2xT9TVVhPn69rdx/x2KH+1IPx5kToO8H1evCKwz7eAqh5V1URn9k2gsc+6fc7PnUA00PBygtDLuIvH+Je9Jybobf0cnduX3z3lGaqTeGV4expXKRboqC6ZPxPEGqCmiFQVkTxAH+AvdyOJiO8l/C7AVmd5MRHJ60yXBK4HUl7cTle+fPk4evSo/UPKRlSVo0ePki9fvkCHYox/bP4YXTCIzZ6q3CWTeOOu9tSvGBHoqC6L365BqKpLREYBS4EwYJaq/ioiU/A2aRYBo0WkC97rDMfwXrQGuAb4t4h48Caxqfr3u5/SVbFiReLi4jh8+DDgPe8dqv+YslPd8+XLR8WK2atLAWMyxfoP0EWjWKdX81D4Y7w9vA01Sufch0f9+qCcqi4BlqRYNtFnejzeu5tSbrcKqHelxw8PD6dq1aoX5qOjo2nY8LLOVOV4oVx3Y7LEmrdg8YP8qPV5PP+jzB5+I5VLFAh0VFckdJ6kNsYYf/nxVVj6KMu1EVMLjWfOiBsoVzR/oKO6YpYgjDHmcqnCd89D9DN86WnOq8UeYc6wlpQqnDfQkWUKSxDGGHM5VOHrx2HVKyx0t+L90mN5f2gLihX8e08HOZUlCGOMuVQeDyx+ANa9w3vum1lc4Z+8P7gZhfOFBzqyTGUJwhhjLoU7GT67BzYv4DVXF9ZUG8XsgU3IFx4W6MgynSUIY4zJKFci+tFgZNsSnk/uzZ91RvLv26PIkzs4h9axBGGMMRmRdAad1x/ZuZxJyYNIajyMl7vVIyyXBDoyv7EEYYwx6Tl3HM8HvSBuHQ8nj6DY9UN5omMtRII3OYAlCGOMSdvpg3je74b70HZGJY2m7k0DGNW2RtAnB7AEYYwxF3d8N57Z3Ug6uZ9hSWO5pXMfBraIDHRUWcYShDHGpObQVtzvdePsmXgGJz3GHbf3oGtUhUBHlaUsQRhjTEp71+F+vwfHE2GIaxIP3NGNNjlhiNBMZgnCGGN87YzGM7cfB5ILMYwJPHnnbTSJLB7oqALCEoQxxpz366d4Fo5gh6cMo3NPZNqdHbimXJFARxUwliCMMQZgzdvo4gdZr1fxeIHHeWNYW6qUKBjoqALKEoQxJrSpwvcvwPKnWe5pxIwSjzJ7aKug6ZH1SliCMMaELo8H/vsI/DyTj92t+E+lR5h9R/Og63TvclmCMMaEJlcS+tlIZMtCZrpuZWOtf/JWn0bkzR18ne5dLksQxpjQk3gaz7wB5NoVzTPJfTnXdBTTu9QJ6n6VLoclCGNMaIk/hHtOTziwmbHJd1G57XDGh0jXGZfKEoQxJnQc3YH7vX+QfPIA9yQ/yM1d76Bvs8qBjirbsgRhjAkNe3/BPacnp88lMcI9gbsG9Oama8oEOqpszRKEMSb4xS7DPW8gB1yFuEee4onhXWlYuVigo8r2LEEYY4Lbxnl4PruX3z0VGF9gIi8N7UC1UoUCHVWOYAnCGBOcVGHF/8G3T/KTpzYvlZjEzKGtKV04X6AjyzEsQRhjgo/bhS4Zi6x7h0/d17OoynhmDWxBobz2L+9S+HWkbRHpICLbRCRWRMalsn6wiBwWkQ3Oa5jPukEist15DfJnnMaYIJJ0Bs+8fsi6d3jN1YUf6z3NzCHXW3K4DH77jYlIGPAqcDMQB6wRkUWqGpOi6HxVHZVi2+LAJKAJoMA6Z9vj/orXGJPzhSedwD2rE3JgExOSh1C67b08Z884XDZ/tiCaAbGqulNVk4B5QNcMbnsL8LWqHnOSwtdABz/FaYwJBkdiabDuYZIPxHB38j+J6j6W0TfVtORwBfzZ5qoA7PGZjwOap1Kuh4i0An4H/qmqey6y7d/G+hOREcAIgDJlyhAdHZ1mQPHx8emWCVahWnerd2goeiKGazY/Q5IL7nRP4MZGdSl5Opbo6NhAh5Yl/PV++zNBpJa2NcX858BcVU0UkZHAbKBtBrdFVWcCMwGaNGmirVu3TjOg6Oho0isTrEK17lbvELD5YzzfT+RPd0nul4d5blRPapUNrUF+/PV++/MUUxxQyWe+IrDPt4CqHlXVRGf2TaBxRrc1xoQ4VVgxDRbeyTpXNR6J+D8GXxsZcsnBn/yZINYANUWkqojkAfoAi3wLiEg5n9kuwFZneinQXkSKiUgxoL2zzBhjwJ2MZ9Fo+GYy/3Ffx5uRLzHrnlsols+vN2aGHL+dYlJVl4iMwvuPPQyYpaq/isgUYK2qLgJGi0gXwAUcAwY72x4TkSfxJhmAKap6zF+xGmNykIRTuOffQdiu5bzi6saxpmN5vXNd66rbD/x6Y7CqLgGWpFg20Wd6PDD+ItvOAmb5Mz5jTA5zYg+uOb3gyO88kjyCWp3u4b7rqwY6qqBlT44YY3KGuHW4PuhNwrkz3O8eR9/+g2hX23pj9SdLEMaY7O/Xz3B/MoL9rqI8lOcZJgzvTt0KRQMdVdCzBGGMyb5U0RXTkG+nsMFTk5dKPMG/BrejbFHrcC8rWIIwxmRPriTci0YTtmku/3Ffx7KaE3mzTzPy5wkLdGQhwxKEMSb7OXsM19z+5N6zipeSe+C64SFebl+LXHanUpayBGGMyV4O/UbynNvRU3t5wDWKlj3upnujioGOKiRZgjDGZB/bv8a1YDAnk8N4MNcURg3rS9PI4oGOKmRZgjDGBJ4q+uOr6FePs81TiakRE3l2SCcqFisQ6MhCmiUIY0xguZJwf/EAYRveZ6m7KV9Un8QbfVtQ0Ab4CTh7B4wxgXPmKMlz+xMe9yPTXd1IvmEc02+2i9HZhSUIY0xgHNhM0pw+aPxBHnSP4sZe99KlQflAR2V8WIIwxmS9mP/gWngXx135GBf+FP8c1of6FSMCHZVJwRKEMSbreDx4lj9DrhUvsMlTg1dLT+a5Qe0oXdiejM6OLEEYY7JG4mmSPx5B+PYlLHDdyKaoibzWrSF5c9uT0dmVJQhjjP8d20XinD7kPvY7T7ruIPLWB3ny2iqI2MXo7MwShDHGv2K/IXnBEBISXYwLm8DgoYNpXq1EoKMyGWAJwhjjH6p4Vv4LvplCrKcCLxabyJQhnakQkT/QkZkMsgRhjMl8ifEkf3I34dsW8YX7WlbWfoJXezYjX7hdb8hJLEEYYzLX0R0kzulL7uPbmerqR7mOD/PsdZF2vSEHsgRhjMk8278mecFQziV5eCz3BAYPHmKd7eVgliCMMVfO48H93fPk+m4q2z2VmV5qEpMH3UqZIvZ8Q05mCcIYc2XOHSdxwTDy7lrGJ+6WbIp6guldG5Mnd65AR2aukCUIY8zl27+JxA/6kSt+P5M9Q6nb9QGeaFIp0FGZTGIJwhhzWXTDh7gXjeG4uyBT8j/NfYP6cU25IoEOy2QiSxDGmEvjSiR58SOEr3+Hn921+bjaFJ7t05qi+cMDHZnJZJYgjDEZd/wPEj4cSL7DG/m36za07URebH2Vjd8QpDJ0FUlEqotIXme6tYiMFpF0++YVkQ4isk1EYkVkXBrleoqIikgTZz5SRM6JyAbn9UZGK2SM8ZNt/yXptZYkHdrOg7kept7glxnZ9mpLDkEsoy2IhUATEakBvA0sAj4EOl1sAxEJA14FbgbigDUiskhVY1KUKwyMBn5KsYsdqhqVwfiMMf7iduH65ilyr3qJ3z2R/LvMRCYMtFtYQ0FGE4RHVV0i8g/gX6r6ioisT2ebZkCsqu4EEJF5QFcgJkW5J4HngbGXELcxJiucPsi5uYPIv+9HPnS1Zf91T/DSLfXIHWa3sIaCjL7LySLSFxgEfOEsS++KVAVgj898nLPsAhFpCFRS1S/4u6oisl5EvhORGzIYpzEms+xaQcKM62HvOibIKMoN+DcPdmpgySGEZLQFMQQYCTytqrtEpCowJ51tUjsxqRdWiuQCXgIGp1JuP1BZVY+KSGPgMxGpo6qn/nIAkRHACIAyZcoQHR2dZkDx8fHplglWoVp3q/dlUDcVd31EtT/nsddTlmfyPk2nRjWQAzFEH0h5AiB7sfc7k6nqJb2AYkD9DJRrASz1mR8PjPeZLwocAXY7rwRgH9AklX1Fp7bc99W4cWNNz/Lly9MtE6xCte5W70t06oCendlRdVIRXTihkz772RpNTHZnamz+ZO/3pQPW6kX+r2b0LqZoESkiIsWBjcA7IjItnc3WADVFpKqI5AH64L24fT4xnVTVkqoaqaqRwGqgi6quFZFSzkVuRKQaUBPYmZFYjTGXaWc0CTNaQNwaJsndFO37NuO6NrEuM0JYRk8xFVXVUyIyDHhHVSeJyKa0NlDvRe1RwFIgDJilqr+KyBS8GWtRGpu3AqaIiAtwAyNV9VgGYzXGXAqPm+RvnyVs5Yvs8ZTntVJP89DAbpS3gX1CXkYTRG4RKQfcDjyW0Z2r6hJgSYplEy9StrXP9EK8t9YaY/zp5F7Ozh9KgX2r+djdir0tnuSFW+rbhWgDZDxBTMHbEvhBVdc4p322+y8sY4y/6W+LSVp4N5qUwKSwUbTrP4aeNUsFOiyTjWQoQajqR8BHPvM7gR7+CsoY40fJCSR++Rh5f3mL7Z5I3qswiYf63UqpwnkDHZnJZjKUIESkIvAKcD3eW1VXAverapwfYzPGZLbDv3PmwzsoeHwr77o74L5pMlNbWXcZJnUZPdH4Dt47kMrjfdjtc2eZMSYnUMW97j2SX7+BxGN7GJ9vAo3vmsmdrWtZcjAXldFrEKVU1TchvCsiY/wRkDEmk507ztmFoygQ+wU/u2vz9TVPMqFHawrmtc6cTdoy+gk5IiIDgLnOfF/gqH9CMsZkFt31PefmDyf83GH+RT+qdh/PxIaVAx2WySEymiCGAjPwdo2hwCq83W8YY7Ih8bhI+HIieX6azgFPGWaWeolRA3pRsViBQIdmcpCM3sX0J9DFd5lziulf/gjKGHMFju7gmjUPk+/cDha423Dixik83bYeYXatwVyiK3ka5oFMi8IYc+VUcf38DkmvXk+esweYlO8Rat31LiPa1bfkYC7LlVylsk+cMdlF/CHiP7qbQn8sY6W7Dh+XHMUzd99OgTx2IdpcvitpQWj6RYwx/ubeuphzLzcjfPd3vJhrCAl9FtKtQXlLDuaKpfkJEpHTpJ4IBLCevIwJpMTTxP/nYQrFfMhOTxU+qvIi9/XuTIlCeYmO3hbo6EwQSDNBqGrhrArEGJNx+scqzswfToEze3mTbhTvPIlJTaoiYmd+TeaxNqgxOUlyAmeWTib/2tc55inJ86VeYHj//lQqbrevmsxnCcKYHEL3ruf0vDspcnoHcz3tSGwzmUk31rE7lIzfWIIwJrtzJ3N22VTy/jiNMxrBtIgnGdB/KDVKFwp0ZCbIWYIwJjs7GMPJucMoeuJXPvXcwNEbnmRC2wY2oI/JEpYgjMmO3MmcXf4ieVa+SLIW4KnCj9JzwN3UKlsk0JGZEGIJwpjs5sAWTs4dTtGTMXzubsHe66bwSPsmhFurwWQxSxDGZBfuZM588zx5V00jSQvwdOFH6d7/bjqXs1aDCQxLEMZkA8vNgNEAABX1SURBVLp/IyfnjSDi5G8s8lzPoZZTeOSmRnatwQSUJQhjAik5gfivnyH/z6+QrIV5tugEevYfSZcy9oyqCTxLEMYEiGf3j5z+aCRFz+zmE8+NnL7xCR5u09CeazDZhiUIY7JaYjwnvnicIpvf4bSW4LWSz9Cv32CqlCgY6MiM+QtLEMZkIdfvX3Nu4SiKJBxkrnQgf4fJjLv2KutDyWRLliCMyQrxhzn2yYMU3/kfDnrK82mllxnUuzeli+QLdGTGXJQlCGP8SZVza95Dlz5GQdc53szdm8r/mMBDDSoHOjJj0uXXe+hEpIOIbBORWBEZl0a5niKiItLEZ9l4Z7ttInKLP+M0xh/0yHaOvtae/EtGsyW5Am/Wfo8+D73KLZYcTA7htxaEiIQBrwI3A3HAGhFZpKoxKcoVBkYDP/ksqw30AeoA5YFlInKVqrr9Fa8xmcaVyKlv/o/8q6cR7gnn5YKjuLHPg4yqXDzQkRlzSfx5iqkZEKuqOwFEZB7QFYhJUe5J4HlgrM+yrsA8VU0EdolIrLO/H/0YrzFXzLXje04vHE2xs7v40tOCIzdM5t62Te2BN5Mj+TNBVAD2+MzHAc19C4hIQ6CSqn4hImNTbLs6xbYVUh5AREYAIwDKlClDdHR0mgHFx8enWyZYhWrds6re4UknKL11FjWPf8cpT2leLjieOvWaUSn8HCtXfO/346dk73do8Ve9/ZkgUrtv78L41iKSC3gJGHyp215YoDoTmAnQpEkTbd26dZoBRUdHk16ZYBWqdfd7vT0ezqyehax4gtyus7yTuycVuz/OpHpVAnrrqr3focVf9fZngogDKvnMVwT2+cwXBuoC0c4fUllgkYh0ycC2xgScZ99Gji24j5InNrLaU5uNURMZeNvNFMhjNwea4ODPT/IaoKaIVAX24r3o3O/8SlU9CZQ8Py8i0cBYVV0rIueAD0VkGt6L1DWBn/0YqzEZd+4ERz6fRLGY90AL8UrEWG7pez932VgNJsj4LUGoqktERgFLgTBglqr+KiJTgLWquiiNbX8VkQV4L2i7gHvtDiYTcB4PZ9a8j349kWLJJ/k4Vwfyd5jIqObX2JPQJij5tS2sqkuAJSmWTbxI2dYp5p8GnvZbcMZcAve+jRxbMJpSJzbwi6cma+q8TN+ut1IkX3igQzPGb+xkqTFpOXuMw59PovjWOYgW4rWIB7ipzxjuKlc00JEZ43eWIIxJjcfNqR/eIiz6KYq7TvNJ2C0U7DCJu5va6SQTOixBGJNC0s6VnFr4T0qe+Z3VntrERD1G71s7UDCv/bmY0GKfeGMcejKOAx8/Qrk9X5CgJXm9zEQ63X4X15YsFOjQjAkISxDGJJ3hyNIXKPzLaxTzeHgvbx+q/+Mx7r7GOtUzoc0ShAldHg+n187F8/UkSiYf5r9cx6mWj9G37XWEW99JxliCMKEpcfdqTix8kDKnt7DJU4211zxJ9649iCiQJ9ChGZNtWIIwIUWP72bfwkepELcYNIK3Sz1M69vvY2hpewramJQsQZjQcO4EBxY/Q/Etsyiuwof5ehPZ9THurF0l0JEZk21ZgjBBTTwujn4znbw/vEBp92mW5LoRT9vH6N2yKWG57HkGY9JiCcIEJ1VObfiMq38YTwn3flZrXXY2HEe3Th2tt1VjMsj+UkzQSdjxA8f/M45ypzZx0FOBpdWfp+M/7uDaIvkDHZoxOYolCBM0kg/EcOCT8VQ6FE0ujWB2yQcIj7yOQZ1vDnRoxuRIliBMjqcn9xL36UTK7/6EopqXDwsPolbXhxlUs2JIDj9pTGaxBGFyrrPHiPviWUrFvEsZdfOfvLdRouOj9I2qZR3qGZMJLEGYnCcxnn1LpxGx/nXKe87xVVgr3K3H07XltXZnkjGZyBKEyTlciRz49nUKrH6J8p4TREtTTrR4mI7tbiJv7rBAR2dM0LEEYbI/t4vDP8wm1/fPUdZ1kJ+ow56G/6Jjh87WBbcxfmR/XSb78rg5svpDNHoqpZLi2KzVWHbNdDp07kvzgtZnkjH+ZgnCZD8eD0fXfozrm6cpk7ibrVqFb2s+T9sug6hXJF+gozMmZFiCMNmHKsfX/4eEr56kXEIssVqB6KpP0fofd9K7aIFAR2dMyLEEYQJPlWO/fEbCsmcof+53dmtZ5leZSMtud9G7uI3mZkygWIIwgaPK0XWfkrjsGconbGe3lmVB5cdo0XUkvUta99vGBJolCJP1PB6OrPuEpG+mXkgMH1V+jBbdRnJ7CUsMxmQXliBM1vG4Obh6Hp7vXqBc4i52a1kWVplAi24j6VW8cKCjM8akYAnC+J87mf0rZhP2w0uUSY4jViuwsOokrus6nB7FLDEYk135NUGISAfgZSAMeEtVp6ZYPxK4F3AD8cAIVY0RkUhgK7DNKbpaVUf6M1bjB8kJ7Il+m/w/Taec6wBbNZIfrnqWG7oMoUdh63rbmOzObwlCRMKAV4GbgThgjYgsUtUYn2IfquobTvkuwDSgg7Nuh6pG+Ss+4z+acIrdS2cQsfFNKnmOsYmarKz9CK1v7c81BfMGOjxjTAb5swXRDIhV1Z0AIjIP6ApcSBCqesqnfEFA/RiP8TP36cPsXPx/lNv2HlX1DD9JfQ43eJrWHXtRP194oMMzxlwiUfXP/2QR6Ql0UNVhzvxAoLmqjkpR7l7gASAP0FZVtzunmH4FfgdOARNUdUUqxxgBjAAoU6ZM43nz5qUZU3x8PIUKheZ99f6se9jZg+TZ9hkNTi4jjybznTRle4XuVK1ei/AA964aqu+51Tu0XEm927Rps05Vm6S6UlX98gJ64b3ucH5+IPBKGuX7AbOd6bxACWe6MbAHKJLW8Ro3bqzpWb58ebplgpU/6n5q1y/626u9NXlShCZNLKZfPd1do1esUJfbk+nHulyh+p5bvUPLldQbWKsX+b/qz1NMcUAln/mKwL40ys8DXgdQ1UQg0ZleJyI7gKuAtf4J1WSYKkc2f83JZS9S/dRPVNB8fFX4H5Rodz/tGtS3gXqMCSL+TBBrgJoiUhXYC/TB20q4QERqqup2Z/ZWYLuzvBRwTFXdIlINqAns9GOsJj3uZPasnAurXqFS4u94NILPSw+nRqfRdKpaOdDRGWP8wG8JQlVdIjIKWIr3NtdZqvqriEzB26RZBIwSkXZAMnAcGORs3gqYIiIuvLfAjlTVY/6K1Vyc5+xxYv/7OsV/nUUl92F2ank+jxxPo84j6VwyItDhGWP8yK/PQajqEmBJimUTfabvv8h2C4GF/ozNpO3coR3sXvx/VPljIVeRwDqpy9r6j9GiQz86F7BbVY0JBfYktfkfVY7EfMfRb/5FjWPR1NBcrMzXilzXjeK6lm0JD8sV6AiNMVnIEoRBkxPY/d37hK35N5UTt5NbC/J1sd6Uu/l+Wte+xi48GxOiLEGEsMQT+9mxZDrltn9IVT1BLBX5MnIc9ToOp0OZkoEOzxgTYJYgQo0qR7b9wKFlr1DzyDJq42J17ibERw3nupt7UCOvPfFsjPGyBBEixJ1I7Fczyb3uLSITt5FX8/Nd0c5E3HgPzRs1tdNIxpi/sQQR5M4c3MnOpTOov3MBxTjNDiqwNHIsdTrcRbuypQMdnjEmG7MEEYw8bv5c8zlnf/g3V538kdrAqlxNcDe/i2vb/oPqeextN8akz/5TBJGEEweJXfo6JbfNpbLnAIe1KN+UGkDZtiNxHTxMmzZtAh2iMSYHsQSR06kSt2EZJ1b8m6uOLacuLjbkqktM3TE0umUgNxf29vAYfSg6sHEaY3IcSxA5VMLJQ8R+NZPiv31IRfdeimgBfojoTNEb7qJh42vtorMx5opZgshJVNmz/itOrHiTq497Wwubc9Xit1qTqdd+EG2KFwt0hMaYIGIJIgc4c2QPsV+9SenYBVTy7KeoFmBVsc5EtBxO/UbXkSvAg/IYY4KTJYhsSt3JxP7wCUlr3uXqU6tpIB42htVlW+17qXfzQFoXs55UjTH+ZQkimzm8cxNxy9+kctzn1NTjHNYIVpTuS+lWw6hft6FdWzDGZBlLENlAwunj/P7NuxSImUeNpN+I0DA25GvG1rp9aXjT7bQpkD/QIRpjQpAliABRt4vYn77g7Jo5XH08mvoks0MqEx15P9XaDqVp5chAh2iMCXGWILLYge2/sPe7WVTZ+wU19TgntSBrit1K4WsHUb9pa6rbmAvGmGzCEkQWOHVkL7HfvEvE9oVUc+2ghIaxMX9TttXpTf02t3NDoUKBDtEYY/7GEoSfJJ49yW/L55H714+4+sw6GomHbbmq8331sdRoO4gmFSoHOkRjjEmTJYhM5HEl8/uPizi3bi61TnxPAxLZRylWlR1AqesGUqt+U662u5CMMTmEJYgrpB43O3/5luM/f0i1Q8uoxSlOakHWF7uF/E36Uu/a9pTPbb9mY0zOY/+5Locqf279iYMr36fy/v9SXY9wTvOwpVALttfpQb3WPbmuQMFAR2mMMVfEEsQl2Pv7evb98AFl9yyhsmcv5TSMLfkas7PWg1zTug9NixUPdIjGGJNpLEGkY1/sZuJWfkDpPYuJdP9JORV+zVOfPVcPoWbrfjQsUyHQIRpjjF9YgkjF3tiN7P1hHiX//JJq7l2UB2Jy12HVVY9Q7cb+1KtQJdAhGmOM31mCcOzZtp59q+ZSOm4pVd27qQD8lvsaVtV4gMgb+lO7So1Ah2iMMVnKrwlCRDoALwNhwFuqOjXF+pHAvYAbiAdGqGqMs248cKezbrSqLvVHjPv/2EbS7B5U8eyhggq/5anNj9UeIvKGPtSqbEnBGBO6/JYgRCQMeBW4GYgD1ojIovMJwPGhqr7hlO8CTAM6iEhtoA9QBygPLBORq1TVndlxlipflc15K7K/cn+qtupD7QpVM/sQxhiTI/mzBdEMiFXVnQAiMg/oClxIEKp6yqd8QUCd6a7APFVNBHaJSKyzvx8zO8jc4Xlo+Mh/M3u3xhiT4/kzQVQA9vjMxwHNUxYSkXuBB4A8QFufbVen2NZuFzLGmCzkzwSRWp8S+rcFqq8Cr4pIP2ACMCij24rICGAEQJkyZYiOjk4zoPj4+HTLBKtQrbvVO7RYvTOXPxNEHFDJZ74isC+N8vOA1y9lW1WdCcwEaNKkibZu3TrNgKKjo0mvTLAK1bpbvUOL1Ttz+XPwgTVATRGpKiJ58F50XuRbQERq+szeCmx3phcBfUQkr4hUBWoCP/sxVmOMMSn4rQWhqi4RGQUsxXub6yxV/VVEpgBrVXURMEpE2gHJwHG8p5dwyi3Ae0HbBdzrjzuYjDHGXJxfn4NQ1SXAkhTLJvpM35/Gtk8DT/svOmOMMWmx8S2NMcakyhKEMcaYVInq3+4ezZFE5DDwRzrFSgJHsiCc7ChU6271Di1W70tXRVVLpbYiaBJERojIWlVtEug4AiFU6271Di1W78xlp5iMMcakyhKEMcaYVIVagpgZ6AACKFTrbvUOLVbvTBRS1yCMMcZkXKi1IIwxxmSQJQhjjDGpCpkEISIdRGSbiMSKyLhAx+MvIjJLRA6JyBafZcVF5GsR2e78LBbIGP1BRCqJyHIR2Soiv4rI/c7yoK67iOQTkZ9FZKNT78nO8qoi8pNT7/lOh5lBR0TCRGS9iHzhzIdKvXeLyGYR2SAia51lmf5ZD4kE4TP8aUegNtDXGdY0GL0LdEixbBzwjarWBL5x5oONC3hQVa8BrgXudd7jYK97ItBWVRsAUXiH7L0WeA54yan3cbzjuwej+4GtPvOhUm+ANqoa5fP8Q6Z/1kMiQeAz/KmqJuEde6JrgGPyC1X9HjiWYnFXYLYzPRvolqVBZQFV3a+qvzjTp/H+06hAkNddveKd2XDnpXhHZ/zYWR509QYQkYp4hwl4y5kXQqDeacj0z3qoJIjUhj8NpSFMy6jqfvD+IwVKBzgevxKRSKAh8BMhUHfnNMsG4BDwNbADOKGqLqdIsH7e/wU8DHic+RKERr3B+yXgKxFZ54ysCX74rPu1u+9sJENDmJqcT0QKAQuBMap6yvulMrg5Y6VEiUgE8ClwTWrFsjYq/xKR24BDqrpORFqfX5xK0aCqt4/rVXWfiJQGvhaR3/xxkFBpQVzq8KfB5qCIlANwfh4KcDx+ISLheJPDB6r6ibM4JOoOoKongGi812AiROT8F8Bg/LxfD3QRkd14Txm3xduiCPZ6A6Cq+5yfh/B+KWiGHz7roZIg0h3+NMgtwhmtz/n5nwDG4hfO+ee3ga2qOs1nVVDXXURKOS0HRCQ/0A7v9ZflQE+nWNDVW1XHq2pFVY3E+/f8rar2J8jrDSAiBUWk8PlpoD2wBT981kPmSWoR6YT3G8b54U+DcrQ6EZkLtMbb/e9BYBLwGbAAqAz8CfRS1ZQXsnM0EWkJrAA2879z0o/ivQ4RtHUXkfp4L0iG4f3Ct0BVp4hINbzfrIsD64EBqpoYuEj9xznFNFZVbwuFejt1/NSZzQ18qKpPi0gJMvmzHjIJwhhjzKUJlVNMxhhjLpElCGOMMamyBGGMMSZVliCMMcakyhKEMcaYVFmCMCFBRNxOz5fnX5nWaZ+IRPr2npuJ+31CRMZm9n6NyahQ6WrDmHOqGhXoIIzJSawFYUKa06/+c86YCj+LSA1neRUR+UZENjk/KzvLy4jIp874CxtF5DpnV2Ei8qYzJsNXzlPNvscp6hwrlzNfQET2iEi4iAwXkTXO/haKSIFU4owWkSbOdEmni4nzHfW94Gy/SUTucpaXE5HvndbSFhG5wV+/QxO8LEGYUJE/xSmm3j7rTqlqM2AG3qftcabfU9X6wAfAdGf5dOA7Z/yFRsCvzvKawKuqWgc4AfTwPbiqngQ2Ajc6izoDS1U1GfhEVZs6+9zKpY1hcCdwUlWbAk2B4SJSFejn7D8KaABsuIR9GgPYKSYTOtI6xTTX5+dLznQLoLsz/T7wvDPdFrgDLvSietIZuWuXqp7/J7wOiEzlOPOB3nj7C+oDvOYsrysiTwERQCFg6SXUqz1QX0TO9z9UFG+yWgPMcjow/MwnNmMyzFoQxvy1S+iL9T2TXp80vv39uEn9y9cioKOIFAcaA986y98FRqlqPWAykC+VbV387+/Vd70A9zkji0WpalVV/coZOKoVsBd4X0TuSCd+Y/7GEoQx3m/153/+6EyvwvstH6A/sNKZ/ga4Gy6c/y+S0YM4I7/9DLwMfOG0QAAKA/udb/v9L7L5brxJBf7XWyl4Wxt3O9siIlc5vX1WwTtewpt4e7ltlNE4jTnPTjGZUJHfGXXtvP+q6vlbXfOKyE94vzD1dZaNxnuK5iHgMDDEWX4/MFNE7sTbUrgb2H8JccwHPsLb4+55j+PtdfYPvL3RFk5luxeBBSIykP+1PMA73GYk8IvT5flhvENNtgYeEpFkIB7ntJgxl8J6czUhzbkbqImqHgl0LMZkN3aKyRhjTKqsBWGMMSZV1oIwxhiTKksQxhhjUmUJwhhjTKosQRhjjEmVJQhjjDGp+n8OkbHkXrdNeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch = np.arange(1,51)\n",
    "plt.plot(epoch,train_log_loss_full,label=\"Train log loss\")\n",
    "plt.plot(epoch,test_log_loss_full,label=\"Test log loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch values\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Vs Epoch\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-k28U1xDsLIO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMokBfs3-2PY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
